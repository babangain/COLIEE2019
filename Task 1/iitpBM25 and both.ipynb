{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "directory = os.getcwd() \n",
    "import nltk\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  0\n",
      "Processing  1\n",
      "Processing  2\n",
      "Processing  3\n",
      "Processing  4\n",
      "Processing  5\n",
      "Processing  6\n",
      "Processing  7\n",
      "Processing  8\n",
      "Processing  9\n",
      "Processing  10\n",
      "Processing  11\n",
      "Processing  12\n",
      "Processing  13\n",
      "Processing  14\n",
      "Processing  15\n",
      "Processing  16\n",
      "Processing  17\n",
      "Processing  18\n",
      "Processing  19\n",
      "Processing  20\n",
      "Processing  21\n",
      "Processing  22\n",
      "Processing  23\n",
      "Processing  24\n",
      "Processing  25\n",
      "Processing  26\n",
      "Processing  27\n",
      "Processing  28\n",
      "Processing  29\n",
      "Processing  30\n",
      "Processing  31\n",
      "Processing  32\n",
      "Processing  33\n",
      "Processing  34\n",
      "Processing  35\n",
      "Processing  36\n",
      "Processing  37\n",
      "Processing  38\n",
      "Processing  39\n",
      "Processing  40\n",
      "Processing  41\n",
      "Processing  42\n",
      "Processing  43\n",
      "Processing  44\n",
      "Processing  45\n",
      "Processing  46\n",
      "Processing  47\n",
      "Processing  48\n",
      "Processing  49\n",
      "Processing  50\n",
      "Processing  51\n",
      "Processing  52\n",
      "Processing  53\n",
      "Processing  54\n",
      "Processing  55\n",
      "Processing  56\n",
      "Processing  57\n",
      "Processing  58\n",
      "Processing  59\n",
      "Processing  60\n"
     ]
    }
   ],
   "source": [
    "# Extract text from inside\n",
    "\n",
    "def preprocess(folder):\n",
    "    no_of_paras = []\n",
    "    current_dir = directory + \"/\"+folder\n",
    "    base_cases = []\n",
    "    noticed_cases = []\n",
    "    paragraphs = []\n",
    "    entailed_fragments = []\n",
    "    list_of_files = sorted(os.listdir(current_dir))\n",
    "    x = 1\n",
    "    y = len(list_of_files)-x\n",
    "    for i in range(y):\n",
    "        print(\"Processing \",i)\n",
    "        f = open(current_dir+'/'+list_of_files[i]+\"/base_case.txt\",\"r\")\n",
    "        paragraph_filenames = sorted(os.listdir(current_dir+'/'+list_of_files[i]+\"/candidates\"))\n",
    "        a = f.read()\n",
    "        base_cases.append(a)\n",
    "        f.close()\n",
    "       # g.close()\n",
    "        \n",
    "        arr = []\n",
    "        no_of_paras.append(len(paragraph_filenames))\n",
    "\n",
    "        for j in range(len(paragraph_filenames)):\n",
    "            g = open(current_dir+'/'+list_of_files[i]+\"/candidates/\"+paragraph_filenames[j],\"r\")\n",
    "            paragraphs.append(g.read())\n",
    "            g.close()\n",
    "    return base_cases,entailed_fragments,paragraphs,no_of_paras,list_of_files,noticed_cases\n",
    "    \n",
    "train_base_cases,train_entailed_fragments, train_paragraphs,train_no_of_paras,train_list_of_files,train_noticed_cases = preprocess('task1_test')\n",
    "    \n",
    "#test_base_cases,test_entailed_fragments, test_paragraphs,test_no_of_paras = preprocess('task1_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_base_cases + train_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labels(data):\n",
    "    labels = []\n",
    "    for i in range(len(train_base_cases)):\n",
    "        labels.append(\"base_case_\"+train_list_of_files[i])\n",
    "    for i in range(len(train_base_cases)):\n",
    "        for j in range(200):\n",
    "            labels.append(\"candidate_\"+train_list_of_files[i]+\"_\"+str(j+1))\n",
    "    return labels\n",
    "labels = gen_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "lemma = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "dict_words = set(nltk.corpus.words.words())\n",
    "def filt(case_docs):\n",
    "    filtered_words =[]\n",
    "    filtered_docs = [ '' for i in range(len(case_docs))]\n",
    "    lemma_docs = [ '' for i in range(len(case_docs))]\n",
    "    for i in range(len(case_docs)):\n",
    "        #print(i)\n",
    "        case_words = re.split(\"(?:(?:[^a-zA-Z]+')|(?:'[^a-zA-Z]+))|(?:[^a-zA-Z']+)\", case_docs[i])\n",
    "        filtered_word_list = [word.lower() for word in case_words if (( len(word) >= 3 and word.isalpha() and word.lower() not in stop_words ))  ]\n",
    "        filtered_words.append(filtered_word_list)\n",
    "        '''or ( len(word) <= 3 and word.isdigit())'''\n",
    "        for word in filtered_word_list:\n",
    "            filtered_docs[i] = filtered_docs[i] + word + \" \"\n",
    "            lemma_docs[i] = lemma_docs[i] + lemma.lemmatize(word) + \" \"\n",
    "    return lemma_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-30 13:19:38,604 : INFO : loading Doc2Vec object from doc2vec_task_1_vec_150_window_10_test_set_minc_2_epoch_50.model\n",
      "2019-03-30 13:19:41,185 : INFO : loading vocabulary recursively from doc2vec_task_1_vec_150_window_10_test_set_minc_2_epoch_50.model.vocabulary.* with mmap=None\n",
      "2019-03-30 13:19:41,188 : INFO : loading trainables recursively from doc2vec_task_1_vec_150_window_10_test_set_minc_2_epoch_50.model.trainables.* with mmap=None\n",
      "2019-03-30 13:19:41,191 : INFO : loading wv recursively from doc2vec_task_1_vec_150_window_10_test_set_minc_2_epoch_50.model.wv.* with mmap=None\n",
      "2019-03-30 13:19:41,193 : INFO : loading docvecs recursively from doc2vec_task_1_vec_150_window_10_test_set_minc_2_epoch_50.model.docvecs.* with mmap=None\n",
      "2019-03-30 13:19:41,195 : INFO : loaded doc2vec_task_1_vec_150_window_10_test_set_minc_2_epoch_50.model\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model = Doc2Vec.load(\"doc2vec_task_1_vec_150_window_10_test_set_minc_2_epoch_50.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1-1 48 IITPdocBM\n",
      "t1-2 154 IITPdocBM\n",
      "t1-3 180 IITPdocBM\n",
      "t1-3 124 IITPdocBM\n",
      "t1-4 137 IITPdocBM\n",
      "t1-4 182 IITPdocBM\n",
      "t1-4 65 IITPdocBM\n",
      "t1-5 174 IITPdocBM\n",
      "t1-5 163 IITPdocBM\n",
      "t1-5 130 IITPdocBM\n",
      "t1-5 110 IITPdocBM\n",
      "t1-5 111 IITPdocBM\n",
      "t1-6 124 IITPdocBM\n",
      "t1-6 62 IITPdocBM\n",
      "t1-6 85 IITPdocBM\n",
      "t1-6 168 IITPdocBM\n",
      "t1-6 187 IITPdocBM\n",
      "t1-6 184 IITPdocBM\n",
      "t1-6 45 IITPdocBM\n",
      "t1-6 167 IITPdocBM\n",
      "t1-6 58 IITPdocBM\n",
      "t1-6 70 IITPdocBM\n",
      "t1-7 178 IITPdocBM\n",
      "t1-7 22 IITPdocBM\n",
      "t1-8 88 IITPdocBM\n",
      "t1-8 157 IITPdocBM\n",
      "t1-8 182 IITPdocBM\n",
      "t1-9 71 IITPdocBM\n",
      "t1-10 180 IITPdocBM\n",
      "t1-10 187 IITPdocBM\n",
      "t1-10 51 IITPdocBM\n",
      "t1-10 154 IITPdocBM\n",
      "t1-11 11 IITPdocBM\n",
      "t1-11 111 IITPdocBM\n",
      "t1-11 25 IITPdocBM\n",
      "t1-11 105 IITPdocBM\n",
      "t1-11 2 IITPdocBM\n",
      "t1-11 49 IITPdocBM\n",
      "t1-11 195 IITPdocBM\n",
      "t1-12 7 IITPdocBM\n",
      "t1-12 124 IITPdocBM\n",
      "t1-12 50 IITPdocBM\n",
      "t1-12 194 IITPdocBM\n",
      "t1-12 11 IITPdocBM\n",
      "t1-12 192 IITPdocBM\n",
      "t1-12 52 IITPdocBM\n",
      "t1-13 95 IITPdocBM\n",
      "t1-14 156 IITPdocBM\n",
      "t1-14 79 IITPdocBM\n",
      "t1-15 18 IITPdocBM\n",
      "t1-16 124 IITPdocBM\n",
      "t1-16 58 IITPdocBM\n",
      "t1-17 127 IITPdocBM\n",
      "t1-17 124 IITPdocBM\n",
      "t1-18 177 IITPdocBM\n",
      "t1-18 136 IITPdocBM\n",
      "t1-19 81 IITPdocBM\n",
      "t1-19 120 IITPdocBM\n",
      "t1-19 11 IITPdocBM\n",
      "t1-19 101 IITPdocBM\n",
      "t1-19 59 IITPdocBM\n",
      "t1-20 180 IITPdocBM\n",
      "t1-20 11 IITPdocBM\n",
      "t1-20 76 IITPdocBM\n",
      "t1-21 151 IITPdocBM\n",
      "t1-21 166 IITPdocBM\n",
      "t1-21 83 IITPdocBM\n",
      "t1-21 42 IITPdocBM\n",
      "t1-21 114 IITPdocBM\n",
      "t1-22 173 IITPdocBM\n",
      "t1-22 6 IITPdocBM\n",
      "t1-22 88 IITPdocBM\n",
      "t1-22 163 IITPdocBM\n",
      "t1-22 189 IITPdocBM\n",
      "t1-22 5 IITPdocBM\n",
      "t1-23 125 IITPdocBM\n",
      "t1-23 14 IITPdocBM\n",
      "t1-23 164 IITPdocBM\n",
      "t1-24 127 IITPdocBM\n",
      "t1-24 104 IITPdocBM\n",
      "t1-24 99 IITPdocBM\n",
      "t1-25 5 IITPdocBM\n",
      "t1-25 95 IITPdocBM\n",
      "t1-25 91 IITPdocBM\n",
      "t1-26 104 IITPdocBM\n",
      "t1-26 114 IITPdocBM\n",
      "t1-27 116 IITPdocBM\n",
      "t1-28 80 IITPdocBM\n",
      "t1-28 191 IITPdocBM\n",
      "t1-28 165 IITPdocBM\n",
      "t1-28 130 IITPdocBM\n",
      "t1-29 22 IITPdocBM\n",
      "t1-29 15 IITPdocBM\n",
      "t1-29 19 IITPdocBM\n",
      "t1-30 9 IITPdocBM\n",
      "t1-30 44 IITPdocBM\n",
      "t1-31 84 IITPdocBM\n",
      "t1-31 66 IITPdocBM\n",
      "t1-32 134 IITPdocBM\n",
      "t1-33 109 IITPdocBM\n",
      "t1-33 26 IITPdocBM\n",
      "t1-34 121 IITPdocBM\n",
      "t1-34 63 IITPdocBM\n",
      "t1-35 2 IITPdocBM\n",
      "t1-35 167 IITPdocBM\n",
      "t1-36 145 IITPdocBM\n",
      "t1-36 51 IITPdocBM\n",
      "t1-36 180 IITPdocBM\n",
      "t1-37 33 IITPdocBM\n",
      "t1-37 165 IITPdocBM\n",
      "t1-38 43 IITPdocBM\n",
      "t1-38 14 IITPdocBM\n",
      "t1-38 94 IITPdocBM\n",
      "t1-38 114 IITPdocBM\n",
      "t1-38 28 IITPdocBM\n",
      "t1-38 142 IITPdocBM\n",
      "t1-39 40 IITPdocBM\n",
      "t1-39 50 IITPdocBM\n",
      "t1-40 128 IITPdocBM\n",
      "t1-41 147 IITPdocBM\n",
      "t1-41 153 IITPdocBM\n",
      "t1-41 195 IITPdocBM\n",
      "t1-42 83 IITPdocBM\n",
      "t1-42 198 IITPdocBM\n",
      "t1-42 13 IITPdocBM\n",
      "t1-42 192 IITPdocBM\n",
      "t1-42 65 IITPdocBM\n",
      "t1-42 179 IITPdocBM\n",
      "t1-43 175 IITPdocBM\n",
      "t1-43 13 IITPdocBM\n",
      "t1-44 11 IITPdocBM\n",
      "t1-44 99 IITPdocBM\n",
      "t1-44 92 IITPdocBM\n",
      "t1-45 45 IITPdocBM\n",
      "t1-45 111 IITPdocBM\n",
      "t1-45 7 IITPdocBM\n",
      "t1-45 132 IITPdocBM\n",
      "t1-45 189 IITPdocBM\n",
      "t1-45 151 IITPdocBM\n",
      "t1-45 41 IITPdocBM\n",
      "t1-45 187 IITPdocBM\n",
      "t1-46 23 IITPdocBM\n",
      "t1-46 102 IITPdocBM\n",
      "t1-46 185 IITPdocBM\n",
      "t1-47 82 IITPdocBM\n",
      "t1-47 49 IITPdocBM\n",
      "t1-47 160 IITPdocBM\n",
      "t1-48 37 IITPdocBM\n",
      "t1-48 179 IITPdocBM\n",
      "t1-48 72 IITPdocBM\n",
      "t1-48 114 IITPdocBM\n",
      "t1-48 123 IITPdocBM\n",
      "t1-48 21 IITPdocBM\n",
      "t1-49 8 IITPdocBM\n",
      "t1-50 150 IITPdocBM\n",
      "t1-50 125 IITPdocBM\n",
      "t1-50 58 IITPdocBM\n",
      "t1-50 64 IITPdocBM\n",
      "t1-50 194 IITPdocBM\n",
      "t1-51 199 IITPdocBM\n",
      "t1-51 58 IITPdocBM\n",
      "t1-52 9 IITPdocBM\n",
      "t1-53 39 IITPdocBM\n",
      "t1-54 177 IITPdocBM\n",
      "t1-54 114 IITPdocBM\n",
      "t1-54 159 IITPdocBM\n",
      "t1-54 12 IITPdocBM\n",
      "t1-54 31 IITPdocBM\n",
      "t1-54 168 IITPdocBM\n",
      "t1-54 11 IITPdocBM\n",
      "t1-54 107 IITPdocBM\n",
      "t1-54 140 IITPdocBM\n",
      "t1-54 7 IITPdocBM\n",
      "t1-55 188 IITPdocBM\n",
      "t1-55 147 IITPdocBM\n",
      "t1-55 117 IITPdocBM\n",
      "t1-56 116 IITPdocBM\n",
      "t1-56 53 IITPdocBM\n",
      "t1-56 7 IITPdocBM\n",
      "t1-56 184 IITPdocBM\n",
      "t1-56 12 IITPdocBM\n",
      "t1-56 71 IITPdocBM\n",
      "t1-57 87 IITPdocBM\n",
      "t1-57 130 IITPdocBM\n",
      "t1-58 6 IITPdocBM\n",
      "t1-58 54 IITPdocBM\n",
      "t1-58 22 IITPdocBM\n",
      "t1-58 14 IITPdocBM\n",
      "t1-58 83 IITPdocBM\n",
      "t1-59 27 IITPdocBM\n",
      "t1-59 92 IITPdocBM\n",
      "t1-59 113 IITPdocBM\n",
      "t1-59 165 IITPdocBM\n",
      "t1-60 168 IITPdocBM\n",
      "t1-60 34 IITPdocBM\n",
      "t1-60 188 IITPdocBM\n",
      "t1-60 109 IITPdocBM\n",
      "t1-61 181 IITPdocBM\n",
      "t1-61 33 IITPdocBM\n",
      "t1-61 131 IITPdocBM\n",
      "t1-61 134 IITPdocBM\n"
     ]
    }
   ],
   "source": [
    "for i in range(61):\n",
    "    lst2 = train_base_cases[i:i+1] + train_paragraphs[i*200:(i+1)*200]\n",
    "    lst3 = filt(lst2)\n",
    "    arr = []\n",
    "    for elem in lst3:\n",
    "        arr.append(elem.split())\n",
    "    corpus = arr\n",
    "    result = get_bm25_weights(corpus, n_jobs=-1)\n",
    "    lst = []\n",
    "    for j in range(200):\n",
    "        a = model.docvecs.similarity(labels[i],\"candidate_\"+train_list_of_files[i]+\"_\"+str(j+1))\n",
    "        b = result[0][j+1]\n",
    "        lst.append((a*b,j+1))\n",
    "    lst.sort(reverse=True)\n",
    "    cutoff = ((lst[0][0] + lst[1][0])/2)*0.80\n",
    "    for j in range(10):\n",
    "        if lst[j][0] > cutoff:\n",
    "            print(\"t1-\"+str(i+1),lst[j][1],\"IITPdocBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(200):\n",
    "    lst.append((result[0][j+1],j+1))\n",
    "lst.sort(reverse=True)\n",
    "cutoff = ((lst[0][0] + lst[1][0])/2)*0.90\n",
    "for j in range(10):\n",
    "    if lst[j][0] > cutoff:\n",
    "        print(\"t1-\"+str(i+1),lst[j][1],\"IITPBM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-75020.47405382311"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "325,1486,855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "588/2421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "468/1486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "a = re.search(\"Baban\",\"I am Baban Gain Baban GAin\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
