{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2 This Code must be construed in accordance with honoring the\n",
      "dignity of individuals and the essential equality of both sexes.\n",
      " 3 (1) The enjoyment of private rights shall commence at birth.\n",
      "(2) Unless otherwise provided by applicable laws, regulations or treaties,\n",
      "foreign nationals shall enjoy private rights.\n",
      "(Age of Majority)\n"
     ]
    }
   ],
   "source": [
    "path = ''\n",
    "import re\n",
    "with open(path+'civil_english.txt') as w:\n",
    "    l = w.read()\n",
    "w.close()\n",
    "def remove_content_within_brackets(test_str):\n",
    "    test_str = re.sub(r'(?m)^\\*.*\\n?', '', test_str)\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            ret += i\n",
    "    return ret\n",
    "#l=remove_content_within_brackets(l)\n",
    "l = re.sub(r'Chapter\\s\\d\\s.*\\n|Chapter\\s.*\\n','',l)\n",
    "l = re.sub(r'Section\\s\\d\\s.*\\n|Section\\s.*\\n','',l)\n",
    "#l = re.sub(r'Section\\s.*\\n','',l)\n",
    "#f = re.split(r'Subsection\\s.*\\nArticle|Section\\s.+\\nArticle|\\(.+\\)\\nArticle|.*\\)\\nArticle|\\.\\nArticle',l)\n",
    "f = re.split(r'\\nArticle',l)\n",
    "print(f[2])\n",
    "print(f[3])\n",
    "for i in range(len(f)):\n",
    "    pattern = re.sub(r'Subsection\\s.*\\n|Section\\s.*\\n','',f[i])\n",
    "    f[i] = pattern\n",
    "f.remove(f[0])\n",
    "data = {}\n",
    "pattern = re.compile(r'\\s\\d+\\s|\\s\\d+-\\d+\\s')\n",
    "for i in f:\n",
    "    try:\n",
    "        key = pattern.findall(i)[0]\n",
    "        data[key] = i\n",
    "    except:\n",
    "        continue\n",
    "list_of_keys = list(data.keys())\n",
    "articles = [data[list_of_keys[i]] for i in range(len(data))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'TestData_en.xml'\n",
    "from xml.etree import cElementTree as ET\n",
    "path = ''\n",
    "with open(path+filename) as r:\n",
    "    xmlstr = r.read()\n",
    "r.close()\n",
    "root = ET.fromstring(xmlstr)\n",
    "t2 = []\n",
    "for page in list(root):\n",
    "    t2.append(page.find('t2').text)#t2 contains queries(for testing) as a list\n",
    "from xml.etree import cElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "with open(path+filename) as r:\n",
    "    xmlstr = r.read()\n",
    "r.close()\n",
    "root = ET.fromstring(xmlstr)\n",
    "t1 = []\n",
    "\n",
    "for page in list(root):\n",
    "    tmp= page.find('t1').text\n",
    "    tmp = remove_content_within_brackets(tmp)\n",
    "    t1.append(tmp[8:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "def getText(nodelist):\n",
    "    for node in nodelist:\n",
    "        if node.nodeType == node.TEXT_NODE :\n",
    "            return node.data.strip()\n",
    "\n",
    "def conv2pd(filename):\n",
    "    xmldoc = minidom.parse(filename)\n",
    "    itemlist = xmldoc.getElementsByTagName('pair')\n",
    "    NUM_ELEM = len(itemlist)\n",
    "    ids = []\n",
    "    for i in range(NUM_ELEM):\n",
    "        ids.append(itemlist[i].attributes['id'].value)\n",
    "    \n",
    "    return ids\n",
    "\n",
    "pair_names = conv2pd(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "dict_words = set(nltk.corpus.words.words())\n",
    "def filt(case_docs):\n",
    "    filtered_words =[]\n",
    "    filtered_docs = [ '' for i in range(len(case_docs))]\n",
    "    lemma_docs = [ '' for i in range(len(case_docs))]\n",
    "    for i in range(len(case_docs)):\n",
    "        case_words = re.split(\"(?:(?:[^a-zA-Z]+')|(?:'[^a-zA-Z]+))|(?:[^a-zA-Z']+)\", case_docs[i])\n",
    "        filtered_word_list = [word.lower() for word in case_words if (( len(word) >= 3 and word.isalpha() and word.lower() not in stop_words ))  ]\n",
    "        filtered_words.append(filtered_word_list)\n",
    "        '''or ( len(word) <= 3 and word.isdigit())'''\n",
    "        for word in filtered_word_list:\n",
    "            filtered_docs[i] = filtered_docs[i] + word + \" \"\n",
    "            lemma_docs[i] = lemma_docs[i] + lemma.lemmatize(word) + \" \"\n",
    "    return lemma_docs\n",
    "lst = t2 + articles\n",
    "lst = filt(lst)\n",
    "vect = TfidfVectorizer()\n",
    "tfidf = vect.fit_transform(lst)\n",
    "tf_idf = (tfidf * tfidf.T).A\n",
    "arr = []\n",
    "for elem in lst:\n",
    "    arr.append(elem.split())\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "corpus = arr\n",
    "result = get_bm25_weights(corpus, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782  3  \n",
      "986  965\n",
      "783  783\n",
      "843  843\n",
      "36  34 \n",
      "415  34 \n",
      "1009  100\n",
      "958  958\n",
      "101  101\n",
      "103  103\n",
      "98  94 \n",
      "111  111\n",
      "120  102\n",
      "115  113\n",
      "115  115\n",
      "818  116\n",
      "174  174\n",
      "586  176\n",
      "555  177\n",
      "201  201\n",
      "230  180\n",
      "269  266\n",
      "267  268\n",
      "273  270\n",
      "244  244\n",
      "238  248\n",
      "356  356\n",
      "378  378\n",
      "380  380\n",
      "387  387\n",
      "391  196\n",
      "398  398\n",
      "398  398\n",
      "398  398\n",
      "398  398\n",
      "398  398\n",
      "399  399\n",
      "403  403\n",
      "409  406\n",
      "449  449\n",
      "457  457\n",
      "447  447\n",
      "462  462\n",
      "479  478\n",
      "474  474\n",
      "412  412\n",
      "474  494\n",
      "493  494\n",
      "493  493\n",
      "519  519\n",
      "706  519\n",
      "465  445\n",
      "454  437\n",
      "445  448\n",
      "588  587\n",
      "587  587\n",
      "588  484\n",
      "590  596\n",
      "599  593\n",
      "196  196\n",
      "594  594\n",
      "395  613\n",
      "644  644\n",
      "650  650\n",
      "653  653\n",
      "104  651\n",
      "209  650\n",
      "286  702\n",
      "209  698\n",
      "209  697\n",
      "716  716\n",
      "717  717\n",
      "718  718\n",
      "774  774\n",
      "777  772\n",
      "780  780\n",
      "766  788\n",
      "787  787\n",
      "789  789\n",
      "782  783\n",
      "887  889\n",
      "887  889\n",
      "887  887\n",
      "772  886\n",
      "887  939\n",
      "940  940\n",
      "938  919\n",
      "921  921\n",
      "928  927\n",
      "923  939\n",
      "951  956\n",
      "958  958\n",
      "968  970\n",
      "969  969\n",
      "968  968\n",
      "973  973\n",
      "363  520\n",
      "447  520\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "count = 0\n",
    "def calc(idx,count):\n",
    "    scores = []\n",
    "    for i in range(len(lst)-len(t2)):\n",
    "        scores.append((result[idx][i+len(t2)],list_of_keys[i]))\n",
    "    scores.sort(reverse=True)\n",
    "    x = scores[0][1].strip()\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == \"-\":\n",
    "            print(int(scores[0][1][:i+1].strip()),t1[idx])\n",
    "            if int(scores[0][1][:i+1].strip()) == int(t1[idx]):\n",
    "                count += 1\n",
    "            return count\n",
    "    print(int(scores[0][1].strip()),t1[idx])\n",
    "    if int(scores[0][1].strip()) == int(t1[idx]):\n",
    "        count += 1\n",
    "    return count\n",
    "for i in range(len(t2)):\n",
    "    count = calc(i, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
